---
title: Config and SetUp
description: OLake S3 writer configuration
sidebar_position: 2
---

# S3 Parquet

OLake supports writing in parquet format directly to S3. Before proceeding with the S3 Parquet destination, we recommend reviewing the [Getting Started](/docs/getting-started/quickstart) and [Installation](/docs/install/olake-ui) sections.

## Prerequisites
- Before setting up the destination, make sure you have successfully set up the [`source`](/docs/getting-started/creating-first-pipeline#2-configure-source).
- Review the minimum required [IAM Permissions for S3 Parquet Writer](/docs/writers/parquet/permission).

## Configuration

<Tabs groupId="S3-parquet" queryString="S3">

<TabItem value="OLake-UI" label="OLake UI" default>

<S3ConfigUIDetails/>
---

## Create an S3-compatible destination in OLake UI

Steps to get started:-

1. Navigate to Destinations Tab.
2. Click on `+ Create Destination`.
3. Select `AWS S3` as the Destination type from Connector drop down.
4. Fill in the required connection details in the form.
5. Click on `Create ->`.
6. OLake will test the destination connection and display the results. If the connection is successful, you will see a success message. If there are any issues, OLake will provide error messages to help you troubleshoot.


This will create a S3 destination in OLake, now you can use this destination in your [Jobs Pipeline](../../jobs/overview) to sync data from any [Source](../../connectors/overview) to [AWS S3](../../writers/parquet/s3).

![olake-destination](/img/docs/s3/s3-destination.png)


### Using AWS Amazon S3 Credentials {#s3-cli-configuration-definition}

OLake supports direct syncing of data from source to AWS S3 using Amazon S3 credentials.\
For this, refer to [IAM permission](/docs/writers/parquet/permission) needed for Amazon-powered AWS S3.
User needs to provide,
- AWS S3 bucket path
- AWS S3 access key and secret key
- AWS S3 region
- AWS S3 path (if any)
- AWS S3 endpoint (required only for s3-compatible storage systems other than AWS S3. Refer to [`S3 Endpoint Doc`](https://docs.aws.amazon.com/general/latest/gr/s3.html))

![olake-s3-bucket](/img/docs/s3/olake-s3-bucket.webp)
:::note
If using AWS IAM Role with the required permissions, the AWS Access Key and Secret Key fields can be left blank.
:::

### Using GCS-compatible S3 Credentials

OLake supports writing data to Google Cloud Storage (GCS) in parquet format. 

Google Cloud Storage provides an S3-compatible interface, allowing you to use S3-compatible tools and libraries to interact with GCS buckets and objects. This interoperability enables seamless integration and ingestion of data into GCS by supporting the Amazon S3 API, which means you can use existing S3 tools and workflows with minimal changes such as updating the endpoint to `https://storage.googleapis.com` and authenticating via HMAC keys (discussed in next section). This compatibility simplifies migrations, data transfers, and tool usage across platforms.
For role based permissions, refer to [GCP IAM Permission](/docs/writers/parquet/permission#2-gcs-google-cloud-storage-iam-policy).

#### Creation of HMAC Keys

- HMAC keys will act as the access key and secret key for S3 writer. 
- In Google Cloud Console, go to storage, then settings, then select Interoperability.
- Copy the request endpoint and provide it as the S3 endpoint in OLake.
- Create HMAC keys for the service account, which will have an access key and corresponding secret key.
- Use those HMAC keys as S3 access key and secret key.

:::info
HMAC (Hash-based Message Authentication Code) keys in Google Cloud Storage are used for authentication when accessing GCS resources, particularly through the S3-compatible API. They consist of an access key and a secret key, which provide a way to sign requests and verify identity without using Google account credentials. \

Refer - https://cloud.google.com/storage/docs/authentication/hmackeys
:::

![olake-gcs-s3](/img/docs/s3/GCS-HMAC-Keys.png)

### Using Minio S3 Credentials

OLake supports S3-compatible MinIO as well in its S3 destination configuration.

User can create a MinIO service account, create bucket in it, and provide MinIO access key, secret key with bucket URL in the config. \
In S3 endpoint, URL through MinIO bucket is accessible has to be provided.

:::note
MinIO destination configuration was tested by spinninig up the MinIO docker container and this was in the same directory where OLake's UI backend is present. 
OLake UI docker container was spin up.
:::

![olake-minio-s3](/img/docs/s3/s3-minio-config.png)
</TabItem>

<TabItem value="OLake-CLI" label="OLake CLI" default>

<S3ConfigDetails/>
---

## Create an S3-compatible destination in OLake CLI

To enable S3 or S3 compatible writes, you must create a destination.json file with the configuration parameters listed below. The sample configuration provided here outlines the necessary keys and their expected values.
- Depending upon from where (source - [Postgres](../../connectors/postgres/config), [Mongodb](../../connectors/mongodb/config), [MySQL](../../connectors/mysql/config), [Oracle](../../connectors/oracle/config)) to where you would like to sync the data, you can choose the below S3 destination configurations.

### Using AWS Amazon S3 Credentials
:::info
- For more information on the keys and value of S3 config, refer to this [`S3 Config Info`](#s3-cli-configuration-definition).
:::
<S3Config/>

### Using GCS-compatible S3 Credentials
:::info
In this, create HMAC keys through GCS service account and provide `s3_endpoint: "https://storage.googleapis.com"`. 
For more information on creation of HMAC keys, refer to this [`GCP HMAC Keys`](/docs/writers/parquet/config?S3=OLake-UI#creation-of-hmac-keys).
:::

<S3ConfigGCS/>

### Using Minio S3 Credentials
:::note
MinIO destination configuration was tested by spinninig up the MinIO docker container and this was in the same directory where OLake's CLI backend is present.
Please change the `s3_endpoint` in the current config below and provide the actual MinIO storage URL.
:::
<S3ConfigMinIO/>

### Using Local
- Using Docker
  :::note
  If using docker, mounted path has to be used. `"local_path": "/mnt/config"`, where "/mnt/config" is the local directory in the Docker container where Parquet files will be stored. This path is mapped to your host file system via a Docker volume.
  :::
  <DockerParquetConfig/>

- Using Local system
  <LocalParquetConfig/>

</TabItem>
</Tabs>

---

:::info
1. The generated `.parquet` files use SNAPPY compression ([Read more](https://en.wikipedia.org/wiki/Snappy_(compression))). Note that SNAPPY is no longer supported by S3 Select when performing queries.  
2. OLake creates a test folder named `olake_writer_test` containing a single text file (`.txt`) with the content:
   ```text
   S3 write test
   ```
   This is used to verify that you have the necessary permissions to write to S3.
:::